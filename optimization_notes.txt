Overview
--------

This file includes some general notes about outstanding optimizations
that can still be made.

We can break the operations of the innermost loop of calc_vsf_props
function into 3 distinct steps:

1. distance and absolute velocity difference calculation
2. identification of distance bin index
3. statistic update within the appropriate distance bin

For the range of arguments that calc_vsf_props currently be accepted,
only the first step can be vectorized in the general case. The
branching and introduced in the remaining parts prevents vectorization
in the other cases.

As an aside, this shows the potential advantages of using an algorithm
in which approximate distances are computed using kd-trees or
octrees. Using such approximate distances can allow you to compute the
statistics in a single distance bin (or a very small number of
distance bins) at a time. This essentially removes all branching and
facillitates vectorization of the entire innermost loop. However, such
an approach is complicated to implement and its unclear what
conditions are necessary for the time savings within the loop to
compensate for the overhead of the approximate distance calculations.


Below I'll walk through some thoughts for vectorizing each step. Note
that this discussion is mostly hypothetical (I mostly wanted to
record my ideas). Before any optimizations are made, the code should
probably be profiled.

distance and absolute velocity difference calculation
-----------------------------------------------------

At the time of writing, it seems unlikely that the distance and
absolute velocity difference are actually vectorized (obviously this
should be checked).

Broadly speaking vectorizing this step can be vectorized by computing
distances/velocity differences in batches. These results would be stored
in a small buffer (the exact size) and after the remaining steps would be
performed after the buffer is filled. In detail, there are a few other
factors to be considered:

- the c standard library's sqrt operation does not vectorize. While
  it's possible to implement a vectorized version, it would be easy to
  defer the sqrt operation to one of the other non-vectorizable steps.
  (In other words, this step would just compute the squared distance
  and the squared velocity difference)

- We might need to explicitly unroll the loops that fill the buffer to
  demonstrate to coax the compiler into producing vectorized code. We
  also need to be mindful of C++'s aliasing rules if we factor this out
  into a separate function.

- We need to think about how to fill the buffer at the start and end
  of the innermost loop. The difference in the loop bounds when the
  vsf is computed for a single collection of points compared to the
  loop bounds when computing the vsf for two pairs of points is
  definitely relevant. This might take additional work if we need to
  explicitly unroll the loops that fill the buffer.

- Currently the positions and velocities are organized such that the
  the dimension changes along the slow indexing axis. For this
  approach, this memory layout should be faster (the other layout
  requires shuffles). However some work is needed to:
  - make sure that the start of each dimension has the appropriate
    alignment (i.e. the array probably needs to be padded or we need
    to allocate separate arrays for each dimension)
  - inform the compiler of the alignment of each dimension. This might
    involve writing separate code for 1d distances, 2d distances, and
    3d distances.

As a short term solution, (without vectorization) it might be faster
to change the memory layout order to match scipy (i.e. the dimensions
vary over the fast axis).

identification of distance bin index
------------------------------------

In the case of having bins with a constant linear spacing, it's actually
possible to vectorize this operation (if the first step has been modified
to operate in batches). However, that would involve defining a vectorized
sqrt function.

In the general case, it would be faster to recompute the bin edges in
terms of the squared distances. This would allow us to avoid taking a sqrt
of the distance in either this step or the previous step (which would
always provide at least some speed).

Currently the algorithm uses linear bisection to indentify the correct bin.
In the case of having relatively few bins, it might be worth changing the
search algorithm to avoid branches. This involves using linear search (that
always checks every bin) or a branchless bisection search (a search that
always goes through the maximum number of iterations). SUch a linear search
could actually be vectorized. Note that the changes discussed in this last
paragraph probably won't provide enough performance benefit to be warranted

statistic update within the appropriate distance bin
----------------------------------------------------

There aren't many optimizations to discuss for this step (due to the
branching that directly preceedes this step).

However, in the event that the first step is optimized to employ
vectorization, it might be worth considering the implementation of
these algorithms to use single precision floating point values and
compensated summation (aka Kahan summation). The thinking here is
that the use of single precision floats alongside compensated summation
MIGHT provide a speedup (the speedup comes from the first step) over
double precision without sacrificing too much accuracy. However, this
definitely seems like a bit of a stretch.
